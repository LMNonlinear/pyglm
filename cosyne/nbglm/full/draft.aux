\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Zhou2012}
\citation{Scott2012}
\citation{Zhou2012}
\citation{Pillow2008}
\citation{Mitchell1988}
\gdef\hy@title{Fully Bayesian inference of interpretable structure underlying neural spike trains}
\thanksnewlabel{e1@email}{{swl@seas.harvard.edu}{1}}
\thanksnewlabel{e2@email}{{rpa@seas.harvard.edu}{1}}
\thanksnewlabel{e3@email}{{pillow@princeton.edu}{1}}
\thanksnewlabel{t1thanks}{{\ensuremath  {*}}{1}}
\thanksnewlabel{t2thanks}{{\ensuremath  {\dagger }}{1}}
\thanksnewlabel{t3thanks}{{\ensuremath  {\ddagger }}{1}}
\gdef\hy@author{Scott W. Linderman,, Ryan P. Adams, and Jonathan W. Pillow }
\gdef\hy@keywords{}
\gdef\author@num{3}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Model}{1}{section.2}}
\citation{Pillow2008}
\citation{Hoff2008,Lloyd2012}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:er}{{1a}{2}{Erd\H {o}s-Renyi\relax }{figure.caption.1}{}}
\newlabel{sub@fig:er}{{a}{2}{Erd\H {o}s-Renyi\relax }{figure.caption.1}{}}
\newlabel{fig:sbm}{{1b}{2}{SBM\relax }{figure.caption.1}{}}
\newlabel{sub@fig:sbm}{{b}{2}{SBM\relax }{figure.caption.1}{}}
\newlabel{fig:distance}{{1c}{2}{Latent Distance\relax }{figure.caption.1}{}}
\newlabel{sub@fig:distance}{{c}{2}{Latent Distance\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples from a variety of network models. (a) An Erd\H {o}s-Renyi random graph with independent Bernoulli entries in\nobreakspace  {}$\boldsymbol  {A}$ and Gaussian-distributed weights. (b) A stochastic block model (SBM) with 3 blocks. The block affiliations govern both the weight and the connection probability. (c) A latent distance model in which nearby neurons have dense, excitatory interactions whereas distant neurons have sparse, inhibitory interactions.\relax }}{2}{figure.caption.1}}
\newlabel{fig:network_models}{{1}{2}{Examples from a variety of network models. (a) An Erd\H {o}s-Renyi random graph with independent Bernoulli entries in~$\bA $ and Gaussian-distributed weights. (b) A stochastic block model (SBM) with 3 blocks. The block affiliations govern both the weight and the connection probability. (c) A latent distance model in which nearby neurons have dense, excitatory interactions whereas distant neurons have sparse, inhibitory interactions.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Modeling the Network}{2}{subsection.2.1}}
\newlabel{eqn:glm_ir}{{8}{2}{Modeling the Network}{equation.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Interpretable Latent Network Structure}{2}{figure.caption.1}}
\@writefile{toc}{\contentsline {paragraph}{Erd\H {o}s-Renyi Networks.}{2}{section*.2}}
\newlabel{eq:er_A}{{9}{2}{Erd\H {o}s-Renyi Networks}{equation.2.9}{}}
\newlabel{eq:er_W}{{10}{2}{Erd\H {o}s-Renyi Networks}{equation.2.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Stochastic Block Models (SBM's).}{2}{section*.3}}
\citation{Zhou2012}
\citation{Zhou2012}
\@writefile{toc}{\contentsline {paragraph}{Latent Distance Models.}{3}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Composing Network Models.}{3}{section*.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bayesian Inference}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Gibbs Sampling the Latent Network Parameters}{4}{subsection.3.1}}
\newlabel{eq:x}{{22}{4}{Gibbs Sampling the Latent Network Parameters}{equation.3.22}{}}
\@writefile{toc}{\contentsline {paragraph}{Joint Gibbs update of\nobreakspace  {}$A_{n' \to n}$ and\nobreakspace  {}$\boldsymbol  {w}_{n' \to n}$}{4}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{Gibbs updates of\nobreakspace  {}$\boldsymbol  {\mu }_{n' \to n}$ and\nobreakspace  {}$\boldsymbol  {\Sigma }_{n' \to n}$}{4}{section*.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Collapsing Gibbs Sampling of the Latent Network Parameters}{4}{section.4}}
\bibstyle{imsart-nameyear}
\bibdata{draft}
\bibcite{Engelhardt2014}{{1}{2014}{{Engelhardt and Adams}}{{}}}
\bibcite{Hoff2008}{{2}{2008}{{Hoff}}{{}}}
\bibcite{Lloyd2012}{{3}{2012}{{Lloyd et~al.}}{{}}}
\bibcite{Mitchell1988}{{4}{1988}{{Mitchell and Beauchamp}}{{}}}
\bibcite{Pillow2008}{{5}{2008}{{Pillow et~al.}}{{}}}
\bibcite{Scott2012}{{6}{2012}{{Scott and Pillow}}{{}}}
\bibcite{Zhou2012}{{7}{2012}{{Zhou et~al.}}{{}}}
\@writefile{toc}{\contentsline {paragraph}{Sampling\nobreakspace  {}$\boldsymbol  {\mu }$,\nobreakspace  {}$\boldsymbol  {\Sigma }$,\nobreakspace  {}$\sigma _b^2$, and\nobreakspace  {}$\sigma _\epsilon ^2$ }{5}{section*.8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{5}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{5}{section.6}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.10}}
\@writefile{toc}{\contentsline {section}{Author's addresses}{6}{section*.11}}
